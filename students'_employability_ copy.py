# -*- coding: utf-8 -*-
"""Students' Employability .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jQocLJ5WaDrhgMI7bbYdr6yvrXcBPQ70

##DATASET

##Installing Kaggle API
"""
import subprocess
import sys
import shutil
import os

# Install Kaggle API (replacing Colab-specific pip commands)
subprocess.check_call([sys.executable, "-m", "pip", "install", "kagglehub"])
print("Kaggle API Installed")


from google.colab import files
files.upload()  # This will prompt you to upload your kaggle.json file

# Move the kaggle.json to the correct location
os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
shutil.copy(kaggle_json_path, os.path.expanduser("~/.kaggle/kaggle.json"))

# Set proper permissions
os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)
import kagglehub

# Download the latest version of the dataset
path = kagglehub.dataset_download("anashamoutni/students-employability-dataset")
print("Path to dataset files:", path)

# Verify the download
import os
# List all files in the dataset folder
print(os.listdir(path))

"""##Load the Dataset"""

import pandas as pd
import os

# Full path to the Excel file
excel_file = os.path.join(path, 'Student-Employability-Datasets.xlsx')

# Load the Excel file
data = pd.read_excel(excel_file)

# Preview the data
print(data.head())
print(data.info())

"""##Phase 1 - DATA PROCESSING

##Clean and Normalize the dataset
"""

from sklearn.preprocessing import MinMaxScaler, LabelEncoder

# Drop the "Name of Student" column
data_cleaned = data.drop(columns=["Name of Student"])

# Normalize numeric columns (Min-Max Scaling)
scaler = MinMaxScaler()
numeric_columns = [
    "GENERAL APPEARANCE", "MANNER OF SPEAKING", "PHYSICAL CONDITION",
    "MENTAL ALERTNESS", "SELF-CONFIDENCE", "ABILITY TO PRESENT IDEAS",
    "COMMUNICATION SKILLS", "Student Performance Rating"
]
# Create the 'COMMUNICATION_SKILLS_TOTAL' interaction term
data_cleaned['COMMUNICATION_SKILLS_TOTAL'] = (
    data_cleaned['COMMUNICATION SKILLS'] + data_cleaned['ABILITY TO PRESENT IDEAS']
)
# Create the 'CONFIDENCE_ALERTNESS' interaction term
data_cleaned['CONFIDENCE_ALERTNESS'] = (
    data_cleaned['SELF-CONFIDENCE'] * data_cleaned['MENTAL ALERTNESS']
)

# Apply MinMaxScaler to numeric columns
data_cleaned[numeric_columns] = scaler.fit_transform(data_cleaned[numeric_columns])

# Encode the "CLASS" column
le = LabelEncoder()
data_cleaned["CLASS"] = le.fit_transform(data_cleaned["CLASS"])

# Preview the cleaned dataset
print(data_cleaned.head())

"""##Phase 2 – Feature Engineering

##Check Feature Correlation
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Compute correlation matrix
correlation_matrix = data_cleaned.corr()

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

"""##Aggregated Features"""

# Example: Create a total "communication-related skills" feature
data_cleaned['COMMUNICATION_SKILLS_TOTAL'] = (
    data_cleaned['COMMUNICATION SKILLS'] + data_cleaned['ABILITY TO PRESENT IDEAS']
)
# Printing feature
print("Aggregate Feature: COMMUNICATION_SKILLS_TOTAL")
print(data_cleaned[['COMMUNICATION SKILLS', 'ABILITY TO PRESENT IDEAS', 'COMMUNICATION_SKILLS_TOTAL']].head())

"""##Interaction Terms"""

# Example: Interaction between self-confidence and mental alertness
data_cleaned['CONFIDENCE_ALERTNESS'] = (
    data_cleaned['SELF-CONFIDENCE'] * data_cleaned['MENTAL ALERTNESS']
)

# Print the updated dataset with the interaction feature
print("Interaction Feature: CONFIDENCE_ALERTNESS")
print(data_cleaned[['SELF-CONFIDENCE', 'MENTAL ALERTNESS', 'CONFIDENCE_ALERTNESS']].head())

"""##Polynomial Features"""

from sklearn.preprocessing import PolynomialFeatures

# Create polynomial features (degree=2)
poly = PolynomialFeatures(degree=2, include_bias=False)
poly_features = poly.fit_transform(data_cleaned[numeric_columns])

# Convert to DataFrame with appropriate column names
poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(numeric_columns))

# Print the first 5 rows of polynomial features
print("Polynomial Features (Degree 2):")
print(poly_df.head())

# Optionally, add polynomial features back to the original dataset
data_cleaned = pd.concat([data_cleaned, poly_df], axis=1)

from sklearn.feature_selection import SelectKBest, f_classif

# Select top 5 features based on ANOVA F-statistic
X = data_cleaned.drop(columns=['CLASS'])
y = data_cleaned['CLASS']
selector = SelectKBest(score_func=f_classif, k=5)
X_new = selector.fit_transform(X, y)

# Get selected feature names
selected_features = X.columns[selector.get_support()]
print("Selected Features:", selected_features)

# Update DataFrame with only selected features
data_cleaned = data_cleaned[selected_features.tolist() + ['CLASS']]

# Printing features
print(data_cleaned.info())
print(data_cleaned.head())

"""##Phase 3 – Data Analysis and Visualization"""

print(data.columns)

# Distribution plots for key features
plt.figure(figsize=(12, 6))
sns.histplot(data_cleaned['COMMUNICATION_SKILLS_TOTAL'], kde=True, color='blue', bins=30)
plt.title("Distribution of Communication Skills Total")
plt.show()

sns.histplot(data_cleaned['CONFIDENCE_ALERTNESS'], kde=True, color='green', bins=30)
plt.title("Distribution of Confidence and Alertness Interaction")
plt.show()

# Pairplot to visualize relationships between features
sns.pairplot(data_cleaned[['COMMUNICATION_SKILLS_TOTAL', 'CONFIDENCE_ALERTNESS', 'MENTAL ALERTNESS', 'SELF-CONFIDENCE', 'CLASS']], hue="CLASS")
plt.show()

# Check class distribution
sns.countplot(x='CLASS', data=data_cleaned)
plt.title("Class Distribution")
plt.show()

# Correlation with the target variable
correlation_with_target = data_cleaned.corr()['CLASS'].sort_values(ascending=False)
sns.heatmap(correlation_with_target.to_frame(), annot=True, cmap='coolwarm', cbar=True)
plt.title("Correlation with Target (CLASS)")
plt.show()

"""##Phase 4 – Model Building

"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Split the data into features (X) and target (y)
X = data_cleaned.drop(columns=['CLASS'])
y = data_cleaned['CLASS']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1. Decision Tree Classifier
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_predictions = dt_model.predict(X_test)
dt_accuracy = accuracy_score(y_test, dt_predictions)

# 2. Random Forest Classifier
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_predictions = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)

# 3. Logistic Regression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train, y_train)
lr_predictions = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_predictions)

# Print the results
print(f"Decision Tree Accuracy: {dt_accuracy:.4f}")
print(f"Random Forest Accuracy: {rf_accuracy:.4f}")
print(f"Logistic Regression Accuracy: {lr_accuracy:.4f}")

# Print classification reports for further evaluation
print("\nDecision Tree Classification Report:")
print(classification_report(y_test, dt_predictions))

print("\nRandom Forest Classification Report:")
print(classification_report(y_test, rf_predictions))

print("\nLogistic Regression Classification Report:")
print(classification_report(y_test, lr_predictions))

# Confusion Matrices
print("\nDecision Tree Confusion Matrix:")
print(confusion_matrix(y_test, dt_predictions))

print("\nRandom Forest Confusion Matrix:")
print(confusion_matrix(y_test, rf_predictions))

print("\nLogistic Regression Confusion Matrix:")
print(confusion_matrix(y_test, lr_predictions))

import joblib

# Save the trained RandomForest model
joblib.dump(rf_model, 'random_forest_model.pkl')

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

# Save the label encoder
joblib.dump(le, 'label_encoder.pkl')

"""##Adding Evaluation Metrics in a Table"""

import pandas as pd

# Create a DataFrame with accuracy, precision, recall, F1 score for each model
results = {
    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression'],
    'Accuracy': [dt_accuracy, rf_accuracy, lr_accuracy],
    'Precision': [classification_report(y_test, dt_predictions, output_dict=True)['1']['precision'],
                  classification_report(y_test, rf_predictions, output_dict=True)['1']['precision'],
                  classification_report(y_test, lr_predictions, output_dict=True)['1']['precision']],
    'Recall': [classification_report(y_test, dt_predictions, output_dict=True)['1']['recall'],
               classification_report(y_test, rf_predictions, output_dict=True)['1']['recall'],
               classification_report(y_test, lr_predictions, output_dict=True)['1']['recall']],
    'F1 Score': [classification_report(y_test, dt_predictions, output_dict=True)['1']['f1-score'],
                 classification_report(y_test, rf_predictions, output_dict=True)['1']['f1-score'],
                 classification_report(y_test, lr_predictions, output_dict=True)['1']['f1-score']]
}

# Convert the results into a DataFrame
results_df = pd.DataFrame(results)
print(results_df)

"""##Phase 5 – Evaluation and Visualization

##Cross-Validation
"""

from sklearn.model_selection import cross_val_score

# Decision Tree Cross-Validation
dt_cv_scores = cross_val_score(dt_model, X, y, cv=5, scoring='accuracy')
dt_cv_mean = dt_cv_scores.mean()

# Random Forest Cross-Validation
rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')
rf_cv_mean = rf_cv_scores.mean()

# Logistic Regression Cross-Validation
lr_cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')
lr_cv_mean = lr_cv_scores.mean()

# Display results
print(f"Decision Tree CV Mean Accuracy: {dt_cv_mean:.4f}")
print(f"Random Forest CV Mean Accuracy: {rf_cv_mean:.4f}")
print(f"Logistic Regression CV Mean Accuracy: {lr_cv_mean:.4f}")
